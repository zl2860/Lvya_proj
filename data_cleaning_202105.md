data\_cleaning\_202105
================
Zongchao
5/4/2021

# Import data

注意：石墨下载下来的 `编号.xlsx` 不知道为什么在r里读取时会是另一个文件。需要先把 `编号.csv`再进行读取：

``` r
data = read_xlsx('./health_development/h_20210503.xlsx') %>%
         mutate(h68 = as.numeric(h68))
# 另存为 *.csv!
code = read_csv('./health_development/编号 (1).csv', col_names = F) %>% select(-X3)
```

# 需要解决的问题

  - 匹配班级编号和年级编号

  - 清理体重

  - 清理身高

## 匹配班级编号和年级编号

``` r
# 创建`school_class`
data = data %>% mutate(school_class = str_sub(ID, 3, 4)) %>% 
  select(school_class,everything())

# 创建`grade`
## 先整理班级花名册
code = code %>% 
  filter(nchar(X1) != 1)

## 匹配学号与班级，该函数返回一个匹配好班级的dataframe
grade_gen = function(df = code){
  class_list = df[which(is.na(code$X2)),1]$X1
  class_idx = c(which(is.na(df$X2)),1991)
  grade_vec = vector()
  for (i in 2:length(class_idx)){
    grade_vec = c(grade_vec, rep(class_list[i-1],class_idx[i] - class_idx[i-1]))
  }
  res = cbind(unlist(grade_vec), df) %>% .[,c(1,3)]
  colnames(res) = c("grade", "ID")
  return(res)
}

## 获取匹配好的数据（班级&学好）
grade_matched = grade_gen()

## 检查匹配结果，最下面那行代码返回True则匹配无误
check_grade = grade_matched %>% filter(is.na(grade))
sum(check_grade[,1] != check_grade[,2]) == 0
```

    ## [1] TRUE

``` r
## 在原始数据集创建 `grade`
data_class_grade = left_join(data, grade_matched) %>%
  select(grade, school_class, ID, everything()) %>%
  mutate(grade = str_sub(grade,1,1))
```

    ## Joining, by = "ID"

共有1859人中共有48人未能匹配上grade，他们的ID在`编号.xlsx`中不能被查询到：

``` r
data_class_grade %>% filter(is.na(grade)) %>%
  select(grade, school_class, ID) %>%
  knitr::kable()
```

| grade | school\_class |       ID |
| :---- | :------------ | -------: |
| NA    | 12            | 11125928 |
| NA    | 13            | 11130098 |
| NA    | 13            | 11130099 |
| NA    | 13            | 11131455 |
| NA    | 15            | 11155866 |
| NA    | 15            | 11159432 |
| NA    | 17            | 11170099 |
| NA    | 19            | 11190099 |
| NA    | 19            | 11190198 |
| NA    | 19            | 11190297 |
| NA    | 22            | 12220099 |
| NA    | 25            | 12256138 |
| NA    | 27            | 12270088 |
| NA    | 27            | 12270089 |
| NA    | 27            | 12270090 |
| NA    | 27            | 12270091 |
| NA    | 27            | 12270092 |
| NA    | 27            | 12270093 |
| NA    | 27            | 12270094 |
| NA    | 27            | 12270095 |
| NA    | 27            | 12270096 |
| NA    | 27            | 12270097 |
| NA    | 27            | 12270098 |
| NA    | 27            | 12270099 |
| NA    | 28            | 12280001 |
| NA    | 28            | 12280002 |
| NA    | 28            | 12280003 |
| NA    | 28            | 12280004 |
| NA    | 28            | 12280005 |
| NA    | 28            | 12280006 |
| NA    | 28            | 12280007 |
| NA    | 28            | 12280008 |
| NA    | 28            | 12280009 |
| NA    | 28            | 12280010 |
| NA    | 28            | 12280011 |
| NA    | 28            | 12280012 |
| NA    | 28            | 12280013 |
| NA    | 29            | 12290009 |
| NA    | 31            | 12315115 |
| NA    | 50            | 15500899 |
| NA    | 51            | 15512962 |
| NA    | 54            | 15540099 |
| NA    | 56            | 15561199 |
| NA    | 56            | 15561298 |
| NA    | 56            | 15561397 |
| NA    | 82            | 18827211 |
| NA    | 84            | 18848528 |
| NA    | 85            | 18859114 |

## 清理体重 & 身高

``` r
# 算众数
## a simpe function for getting mode
getmode = function(v) {
   uniqv = unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

## 算众数
mode = data_class_grade %>% 
  na.omit() %>%
  group_by(grade) %>%
  summarise(weight_mode = getmode(h66),
            height_mode = getmode(h68)) %>%
  rename("h66" = "weight_mode",
         "h68" = "height_mode")
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
## imputation 填体重身高

weight_imp = function(grade, df_mode = mode){
  return(mode[mode[,1] == grade,]$h66)
}

height_imp = function(grade, df_mode = mode){
    return(mode[mode[,1] == grade,]$h68)
  }

wh_imp = function(df = data_class_grade){
  
  res = df %>%
    mutate(h66 = ifelse(is.na(h66)|h66 <= 45, NA, h66),
           h68 = ifelse(!is.na(h68) & h68 > 1 & h68 < 2, h68*100, h68), #身高*100
           h68 = ifelse(is.na(h68)|h68 <= 120, NA, h68)) %>%
    mutate(h66 = ifelse(is.na(h66)&!is.na(grade), map(grade, weight_imp)[[1]], h66),
           h68 = ifelse(is.na(h68)&!is.na(grade), map(grade,height_imp)[[1]], h68))
    
  return(res)
}

### 获取填补后的数据集


data_imp = wh_imp()
```

## Simple check

没有填补的人是不在`编号.xlsx`中被记录的人

``` r
skimr::skim(data_imp$h66)
```

    ## 
    ## Skim summary statistics
    ## 
    ## ── Variable type:numeric ──────────────────────────────────────────────────────────────────────────────────
    ##      variable missing complete    n  mean    sd    p0 p25 p50 p75 p100
    ##  data_imp$h66       4     1855 1859 72.97 18.79 45.65  60  70  80  299
    ##      hist
    ##  ▇▃▁▁▁▁▁▁

``` r
skimr::skim(data_imp$h68)
```

    ## 
    ## Skim summary statistics
    ## 
    ## ── Variable type:numeric ──────────────────────────────────────────────────────────────────────────────────
    ##      variable missing complete    n   mean    sd  p0 p25 p50 p75 p100
    ##  data_imp$h68       8     1851 1859 148.18 11.07 122 140 147 155  250
    ##      hist
    ##  ▂▇▃▁▁▁▁▁

``` r
unique(data_imp$h66)
```

    ##   [1]  60.00  50.00  56.00  61.00  81.00  62.00  51.00  80.00  67.00  65.00
    ##  [11]  63.00  46.00  71.00  64.00  87.00  79.00  74.00  52.00  68.00  59.00
    ##  [21]  72.00  48.00  70.00  75.00  82.00  69.00  54.00 146.00  84.00  66.00
    ##  [31]  85.00  57.00  90.00 100.00  95.00  65.10 101.00     NA  58.00  73.00
    ##  [41]  55.00  77.00  78.00  92.00  49.00  53.00 110.00  72.42  94.00  83.00
    ##  [51] 104.00 130.00  76.00  89.00 102.00 105.00 123.00  45.65  65.45  98.00
    ##  [61]  86.00  93.00 150.00 106.00 145.00 299.00  96.00 149.00  88.00  99.00
    ##  [71]  93.28  91.00 170.00 115.00  97.00  59.10 113.00 140.00 120.00  75.37
    ##  [81] 103.00  50.26 160.00  61.82 118.00  60.45 108.00  47.00  60.28 116.00
    ##  [91] 107.00  73.20  63.30  60.43  72.45 135.00 114.00 109.00 112.00 108.80
    ## [101] 230.00 125.00 121.00 198.00  68.30  86.44 134.00  62.42  58.90 200.00
    ## [111]  61.83  68.59  74.34  76.24 124.00  64.61

``` r
unique(data_imp$h68)
```

    ##  [1] 140.00 126.00 150.00 143.00 125.00 139.00 128.00 130.00 153.00 135.00
    ## [11] 123.00 145.00 144.00 133.00 155.00 124.00 137.00 158.00 210.00 160.00
    ## [21] 149.00 134.00 190.00 142.00 148.00     NA 122.00 146.00 250.00 136.00
    ## [31] 168.00 147.00 199.00 141.00 132.00 163.00 159.00 170.00 154.00 138.00
    ## [41] 180.00 165.00 164.00 152.00 156.00 151.00 162.00 157.00 161.00 166.00
    ## [51] 175.00 169.00 167.00 172.00 174.00 127.00 211.00 200.00 131.00 129.00
    ## [61] 171.00 130.30 189.00 156.14

## 挑选、合成变量(5.5更新)

更新内容：

  - 生成`data_r_1` 更新的内容包含5.4～5.5晚微信提及到的内容

  - 再次处理身高体重（height\>=180, weight\>=200 去掉，身高\*100）

  - 删除未匹配到的样本

### 生成`data_r_1` 更新的内容包含5.4～5.5晚微信提及到的内容

``` r
# 处理depression, h57_58, h7, h27&28
## h90a~h90f: 
## 同意->不同意：1->5的题目：a（不需要recode）
## 同意->不同意：5->1的题目：bcdef（需要recode）

data_r_1 = data_imp %>%
  mutate(h90b = as.numeric(recode(h90b, "1" = "5","2" = "4", "5" = "1", "4" = "2", "3" = "3")),
         h90c = as.numeric(recode(h90c, "1" = "5","2" = "4", "5" = "1", "4" = "2", "3" = "3")),
         h90d = as.numeric(recode(h90d, "1" = "5","2" = "4", "5" = "1", "4" = "2", "3" = "3")),
         h90e = as.numeric(recode(h90e, "1" = "5","2" = "4", "5" = "1", "4" = "2", "3" = "3")),
         h90f = as.numeric(recode(h90f, "1" = "5","2" = "4", "5" = "1", "4" = "2", "3" = "3"))) %>%
  rowwise() %>%
  ## 合成depression
  mutate(depression_score = sum(c_across(h90a:h90f))) %>%
  ## 合成h57_58
  mutate( h57_m = ifelse(h57 == -3, NA, h57),
          h58_m = ifelse(h58 == -3, NA, h58),
          h57_58 = coalesce(h57_m, h58_m)) %>%
  select(-h57_m, -h58_m) %>%
  ## 合成h7
  mutate(h7d = as.numeric(h7d)) %>% 
  rowwise() %>%
  mutate(h7 = sum(c_across(h7a:h7d))) %>%
  ## h27 h28
  mutate(friend_homo = ifelse(h1 == 1, h27, h28),
         friend_heter = ifelse(h1 == 1, h28, h27)) %>%
  select(friend_homo,friend_heter,depression_score, h57_58, h7, everything())

data_r_1 %>%
  head(5) %>%
  knitr::kable()
```

| friend\_homo | friend\_heter | depression\_score | h57\_58 | h7 | grade | school\_class |       ID | xuhao\_h | time\_h             | period\_h | h1 |  h2a | h2b | h2c | h3 | h4 |  h5 |  h6 | h7a | h7b | h7c | h7d | h8a | h8b | h8c | h8d | h8e | h8f | h8g | h8h | h8i | h8j | h8k | h8l | h8m | h9 | h10a | h10b | h10c | h10d | h10e | h10f | h10g | h10h | h10i | h10j | h11 | h12 | h13 | h14 | h15 | h16 | h17 | h18 | h19a | h19b | h19c | h20 | h21 | h22a | h22b | h22c | h23 | h24 | h25 | h26 | h27 | h28 | h29a | h29b | h29c | h29d | h29e | h29f | h30a | h30b | h31a | h31b | h31c | h31d | h32 | h33 | h34 | h35 | h36a | h36b | h36c | h36d | h36e | h36f | h36g | h36h | h36i | h37a | h37b | h37c | h37d | h37e | h37f | h37g | h37h | h38 | h39 | h40a | h40b | h40c | h40d | h40e | h41a | h41b | h41c | h41d | h42a | h42b | h42c | h42d | h43a | h43b | h43c | h43d | h44 | h45a | h45b | h45c | h45d | h45e | h45f | h45g | h45h | h46a | h46b | h46c | h46d | h46e | h46f | h46g | h46h | h46i | h46j | h47 | h48 | h49a | h49b | h49c | h49d | h49e | h49f | h49g | h49h | h49i | h50a | h50b | h50c | h50d | h50e | h50f | h51 | h52 | h53 | h54 | h55a | h55b | h55c | h55d | h55e | h56a | h56b | h56c | h56d | h56e | h56f | h56g | h57 | h58 | h59 | h60 | h61 | h62 | h63 | h64 | h65 | h66 | h67 | h68 | h69 | h70 | h71 | h72 | h73 | h74a | h74b | h74c | h74d | h74e | h75 | h76 | h77 | h78 | h79 | h80a | h80b | h80c | h80d | h80e | h81 | h82 | h83a | h83b | h83c | h83d | h83e | h84a | h84b | h84c | h84d | h84e | h84f | h84g | h84h | h84i…213 | h84i…214 | h84j | h85a | h85b | h85c | h85d | h85e | h85f | h85g | h85h | h85i | h85j | h85k | h86a | h86b | h86c | h86d | h86e | h86f | h86g | h86h | h86i | h86j | h86k | h87a | h87b | h87c | h87d | h87e | h87f | h87g | h87h | h87i | h87j | h87k | h88a | h88b | h88c | h88d | h88e | h88f | h88g | h88h | h88i | h88j | h88k | h89a | h89b | h89c | h89d | h89e | h89f | h89g | h89h | h89i | h89j | h89k | h90a | h90b | h90c | h90d | h90e | h90f | h91a | h91b | h91c | h91d | h91e | h91f | h91g | h91h | h91i | h91j | h91k | h91l | h92 | h93 | h94 | h95 | h96 | h97a | h97b | h97c | h98 | h99 | h100 | h101 | h102 | h103 | h104 | h105 | h106 | h107 | h108a | h108b | h108c | h108d | h108e | h108f | h109 | h110 | h111 | h112 | h113 | h114 | h115 | h116 | h117 | h118 | h119 | h120 | h121 | h122 | h123 | h124 | h125 | h126a | h126b | h126c | h127 | h128 | h129a | h129b | h129c | h129d | h129e | h129f | h129g | h129h | h129i | h130 | h131 | h132 | h133 | h134 | h135 | h136 | h137 | h138 | h139a | h139b | h139c | h139d | h139e | h139f | h139g | h139h | h139i | h139j | h139k | h140 | h141a | h141b | h141c | h141d | h141e | h142a | h142b | h142c | h143a | h143b | h143c | h144 | h145 | h146a | h146b | h146c | h146d | h146e | h146f | h146g | h146h | h146i | h146j | h146k | h146l | h146m | h147 | h148a | h148b | h148c | h148d | h148e | h148f | h148g | h148h | h148i | h148j | h149a | h149b | g149c | h149d | h149e | h149f | h150a | h150b | h150c | h150d | h150e | h150f | h150g | h150h | h150i | h151a | h151b | h151c | h151d | h151e | h151f | h151g | h151h | h151i | h151j | mima\_h | school\_h | intervention\_h | public\_h |
| -----------: | ------------: | ----------------: | ------: | -: | :---- | :------------ | -------: | -------: | :------------------ | --------: | -: | ---: | --: | --: | -: | -: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | -: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | --: | --: | --: | --: | ---: | ---: | ---: | --: | --: | ---: | ---: | ---: | --: | --: | --: | --: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | --: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | --: | ---: | ---: | ---: | ---: | ---: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | -------: | -------: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | --: | --: | --: | --: | --: | ---: | ---: | ---: | --: | --: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ----: | ----: | ----: | ---: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ---: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ---: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | ----: | :------ | --------: | --------------: | --------: |
|            7 |             1 |                15 |       1 |  1 | 四     | 11            | 11111127 |      209 | 2020-12-15 13:48:08 |      2455 |  2 | 2011 |   8 |  12 |  1 |  2 | \-3 | \-3 |   0 |   0 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |  2 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |   1 |   7 |   4 |   7 |   6 |   4 |   1 |   2 |    1 |    5 |    5 |   1 |   1 |    1 |    2 |    2 |   7 |   4 |   5 |   2 |   1 |   7 |    2 |    1 |    3 |    2 |    1 |    4 |    4 |    4 |    4 |    3 |    2 |    1 |   7 |   3 |   2 |   1 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   3 |   2 |    1 |    1 |    2 |    2 |    1 |    1 |    2 |    1 |    2 |    2 |    1 |    2 |    1 |    1 |    3 |    2 |    4 |   4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 |    1 |    0 |    1 |    0 |    0 |    1 |    0 |    0 |    0 |    1 |    2 |    1 |    2 |    1 |    2 |   2 |   3 |   2 |   3 |    0 |    1 |    0 |    1 |    0 |    2 |    1 |    2 |    1 |    2 |    1 |    1 | \-3 |   1 |   2 | \-3 |   1 |   2 |   2 | \-3 |   1 |  60 |   5 | 140 |   3 |   2 |   2 |   2 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 | \-3 | \-3 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 |    3 |    4 |    4 |    3 |    4 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |        0 |        1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    1 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    1 |    1 |    2 |    2 |    4 |    5 |    1 |    2 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |   3 |   4 |   1 |   4 |   4 |  \-3 |  \-3 |  \-3 |   4 |   1 |    8 |  \-3 |    8 |  \-3 |    1 |   19 |    4 |    4 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    7 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |  \-3 |  \-3 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    4 |  \-3 |    4 |  \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    2 |     2 |     1 |     4 |     3 |     4 |     1 |     2 |     3 |     1 |     1 |     1 |    1 |    2 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |    2 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 | 1111.0  |        11 |               0 |         0 |
|            7 |             7 |                18 |       1 | 30 | 四     | 11            | 11111239 |      257 | 2020-12-15 13:58:01 |      3105 |  1 | 2011 |   7 |  23 |  1 |  1 |   1 |   2 |   7 |   5 |   8 |  10 |   0 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   0 |   1 |   1 |   0 |   0 |  5 |    0 |    0 |    1 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |   1 |   7 |   4 |   7 |   6 |   2 |   1 |   2 |    1 |    4 |    5 |   1 |   2 |    4 |    3 |    4 |   7 |   4 |   6 |   1 |   7 |   7 |    2 |    2 |    2 |    3 |    2 |    2 |    4 |    3 |    2 |    2 |    2 |    2 |   7 |   3 |   2 |   1 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   3 |   1 |    1 |    1 |    1 |    1 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    3 |    3 |    3 |    3 |   2 |    0 |    0 |    0 |    1 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    1 |    1 |   2 |   3 |    0 |    0 |    1 |    0 |    1 |    1 |    0 |    0 |    0 |    2 |    2 |    2 |    2 |    2 |    2 |   6 |   1 |   1 |   3 |    1 |    0 |    0 |    0 |    0 |    1 |    2 |    1 |    1 |    1 |    1 |    1 |   1 | \-3 |   2 | \-3 |   2 | \-3 |   2 | \-3 |   1 |  50 |   2 | 140 |   2 |   2 | \-3 | \-3 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 | \-3 |   2 |   1 |    1 |    0 |    0 |    1 |    0 |   2 |   5 |    3 |    3 |    3 |    4 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |        0 |        0 |    0 |    0 |    0 |    0 |    1 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    3 |    3 |    3 |    3 |    3 |    3 |    1 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |    2 |   2 |   2 |   1 |   3 |   3 |    3 |    3 |    3 |   3 |   4 |    8 |  \-3 |    8 |  \-3 |    2 |   19 |   19 |    4 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    1 |    2 |    1 |    3 |    2 |    5 |     3 |     3 |     3 |    2 |    1 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |    4 |  \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    2 |     4 |     4 |     4 |     2 |     1 |     1 |     1 |     1 |     2 |     2 |     2 |    2 |  \-3 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |    2 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     1 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 | 1111.0  |        11 |               0 |         0 |
|            6 |             1 |                13 |       2 |  3 | 四     | 11            | 11111334 |      173 | 2020-12-15 13:40:39 |      2021 |  1 | 2012 |   8 |  20 |  1 |  2 | \-3 | \-3 |   1 |   2 |   0 |   0 |   1 |   0 |   0 |   0 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |   0 |  3 |    1 |    0 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |   1 |   6 |   4 |   1 |   5 |   3 |   1 |   2 |    3 |    5 |    5 |   1 |   2 |    2 |    1 |    1 |   6 |   4 |   1 |   3 |   6 |   1 |    2 |    3 |    1 |    3 |    4 |    4 |    4 |    4 |    4 |    4 |    4 |    2 |   6 |   2 |   3 |   2 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |   3 |   1 |    1 |    2 |    2 |    2 |    1 |    1 |    2 |    2 |    1 |    1 |    1 |    1 |    1 |    4 |    4 |    4 |    4 |   4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 |    1 |    0 |    0 |    0 |    1 |    1 |    0 |    0 |    0 |    2 |    2 |    2 |    2 |    2 |    2 |   2 |   1 |   1 |   4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    2 |    2 |    1 |    1 |    1 |    1 |    2 |   2 | \-3 |   1 |   2 |   2 | \-3 |   2 | \-3 |   1 |  56 |   2 | 140 |   3 |   2 | \-3 | \-3 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 | \-3 |   2 |   2 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   5 |   5 |    4 |    4 |    4 |    4 |    4 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |        0 |        0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    2 |    3 |    1 |    1 |    5 |    1 |    2 |    3 |    2 |    2 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |    3 |   3 |   1 |   2 |   3 |   3 |    3 |    2 |    2 |   4 |   4 |    8 |  \-3 |    8 |  \-3 |    2 |   13 |   15 |    4 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    7 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |  \-3 |  \-3 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |    4 |  \-3 |    4 |  \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    2 |     4 |     4 |     4 |     4 |     4 |     3 |     3 |     1 |     1 |     1 |     2 |    1 |    2 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |    2 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 | 1111.0  |        11 |               0 |         0 |
|            7 |             3 |                18 |       2 |  3 | 四     | 11            | 11111560 |      236 | 2020-12-15 13:53:16 |      2663 |  1 | 2011 |   3 |   8 |  1 |  1 |   2 |  11 |   0 |   1 |   1 |   1 |   1 |   0 |   0 |   0 |   0 |   0 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |  2 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |   1 |   2 |   3 |   7 |   6 |   3 |   1 |   2 |    4 |    3 |    2 |   1 |   1 |    1 |    2 |    1 |   6 |   3 |   4 |   1 |   7 |   3 |    2 |    3 |    1 |    2 |    4 |    3 |    4 |    4 |    4 |    4 |    2 |    1 |   5 |   3 |   3 |   1 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   3 |   1 |    2 |    1 |    1 |    1 |    1 |    2 |    1 |    3 |    1 |    3 |    3 |    3 |    3 |    3 |    3 |    2 |    4 |   4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    1 |    2 |    1 |    2 |    1 |    1 |   6 |   6 |   6 |   3 |    0 |    0 |    1 |    0 |    0 |    2 |    1 |    1 |    2 |    2 |    1 |    1 |   2 | \-3 |   2 | \-3 |   2 | \-3 |   2 | \-3 |   2 |  61 |   1 | 126 |   2 |   2 | \-3 | \-3 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 | \-3 |   2 |   1 |    0 |    0 |    0 |    1 |    0 |   5 |   5 |    4 |    4 |    4 |    4 |    4 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |        0 |        0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    2 |    2 |    5 |    1 |    5 |    3 |    2 |    2 |    3 |    1 |    1 |    2 |    3 |    1 |    3 |    3 |    1 |    3 |   1 |   4 |   1 |   3 |   4 |    2 |    1 |    2 |   2 |   2 |    1 |    1 |    3 |    1 |    1 |   14 |   10 |    3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |    6 |    2 |    2 |    2 |   11 |    1 |     1 |     3 |     1 |    2 |    2 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    4 |  \-3 |    4 |  \-3 |    4 |  \-3 |  \-3 |  \-3 |  \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    2 |     1 |     4 |     3 |     1 |     2 |     1 |     1 |     3 |     1 |     2 |     1 |    2 |  \-3 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    2 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     1 |     1 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 | 1111.0  |        11 |               0 |         0 |
|            6 |             6 |                23 |       1 |  6 | 四     | 11            | 11111617 |      231 | 2020-12-15 13:52:02 |      2591 |  1 | 2010 |  11 |   2 |  1 |  1 |   5 |   4 |   1 |   1 |   2 |   2 |   1 |   0 |   1 |   0 |   1 |   1 |   1 |   0 |   0 |   0 |   0 |   0 |   0 |  5 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |   1 |   7 |   2 |   1 |   4 |   3 |   2 |   2 |    4 |    3 |    5 |   1 |   1 |    2 |    1 |    1 |   7 |   4 |   1 |   2 |   6 |   6 |    2 |    2 |    3 |    2 |    1 |    4 |    4 |    4 |    4 |    4 |    4 |    1 |   7 |   2 |   2 |   1 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   3 |   2 |    2 |    1 |    1 |    1 |    1 |    1 |    2 |    2 |    2 |    1 |    1 |    1 |    1 |    3 |    4 |    3 |    4 |   2 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    1 |    0 |    0 |    1 |    1 |    1 |   1 |   4 |    1 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    1 |    1 |    1 |    1 |    1 |    2 |   2 |   4 |   4 |   2 |    0 |    0 |    0 |    1 |    0 |    1 |    2 |    1 |    1 |    2 |    1 |    1 |   1 | \-3 |   1 |   1 |   2 | \-3 |   1 |   1 |   1 |  81 |   4 | 150 |   2 |   2 | \-3 | \-3 | \-3 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 | \-3 | \-3 | \-3 |   2 |   2 |  \-3 |  \-3 |  \-3 |  \-3 |  \-3 |   2 |   5 |    2 |    1 |    3 |    2 |    3 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |    0 |        0 |        0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    1 |    1 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    0 |    1 |    1 |    4 |    5 |    5 |    4 |    4 |    2 |    3 |    3 |    3 |    1 |    3 |    3 |    3 |    3 |    3 |    3 |    2 |   3 |   3 |   1 |   4 |   4 |  \-3 |  \-3 |  \-3 |   3 |   2 |    3 |    2 |    8 |  \-3 |    2 |    8 |    5 |    4 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    1 |    2 |    1 |    4 |  \-3 |    1 |    4 |    1 |    4 |    1 |    4 |    5 |    1 |    1 |    3 |    2 |    2 |     3 |     3 |     3 |    2 |    1 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |   \-3 |    1 |    4 |    4 |  \-3 |    1 |    3 |    1 |    1 |    3 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |    1 |     1 |     1 |     1 |     2 |     4 |     1 |     1 |     1 |     1 |     1 |     1 |    1 |    1 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |    1 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     1 |     1 |     0 |     0 |     0 |     1 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     0 |     1 |     0 |     1 |     1 |     0 |     0 |     0 |     0 | 1111.0  |        11 |               0 |         0 |

  - `friend_homo`: 同性
  - `friend_heter`: 异性

h7-兄弟姐妹数有很多乱填的，独生子女只有 89个。

### 处理身高体重，删除未匹配样本

``` r
# 身高*100的修改在前面已经完成修改
t = data_r_1 %>%
  filter(!is.na(grade)) %>% # 去除未匹配到的人
  mutate(h66 = ifelse(h66 > 200, map(grade, weight_imp)[[1]], h66),
         h68 = ifelse(h68 >180, map(grade, height_imp)[[1]], h68)) # 清理身高>180，体重>200的
```

### simple check 0505

``` r
# 看有无漏填身高体重的
sum(is.na(t$h66)) > 0
```

    ## [1] FALSE

``` r
sum(is.na(t$h68)) > 0
```

    ## [1] FALSE

清理后，体重的 `均数，标准差，中位数` 为 72.463545, 16.7899775, 70, 身高的 `均数，标准差，中位数` 为
147.5971507, 9.7813569, 146.

## 5.06更新

对 `知识与态度-重编码版本-20210504.xlsx` 操作:

  - 去除未记录的人

  - 查看多少人是intervention/control

  - 知识得分

  - 态度得分

### 去除未记录样本、算分

``` r
## awareness and attitudes
aa = read_xlsx('./attitudes/知识与态度-重编码版本-20210504.xlsx')
aa = aa %>%
  filter(ID %in% na.omit(code$X2)) #仅保留在记录的人

## 知识得分&态度
column_idx = function(idx, num){
  return(paste("k", as.character(idx), ".", rep(1:num),sep = ""))
}

### 除去了4题+1题attention check
k1 = column_idx(1,20) %>% .[-c(1,3,5,6,10,18)]
k2 = column_idx(2,20) %>% .[-c(7,9,11,14,17,19)]
k3 = column_idx(3,26) %>% .[-c(1,5,6,7,12,16,18,19,25)]
k4 = column_idx(4,19) %>% .[-c(17,19)]
k5 = column_idx(5,30) %>% .[-c(2,24,26)]
k6 = column_idx(6,30) %>% .[-17]
k7 = column_idx(7,24) %>% .[-20]
k8 = column_idx(8,6)

## 知识得分 K1~4

aa = aa %>%
  mutate(k1_score = rowSums(aa[k1]),
         k2_score = rowSums(aa[k2]),
         k3_score = rowSums(aa[k3]),
         k4_score = rowSums(aa[k4]),
         k5_score = rowSums(aa[k5]),
         k6_score = rowSums(aa[k6]),
         k7_score = rowSums(aa[k7]),
         k8_score = rowSums(aa[k8])) %>%
  select(k1_score, k2_score, k3_score, k4_score, k5_score, k6_score, k7_score, k8_score, everything()) %>%
  rowwise() %>%
  mutate(knowledge_total = sum(c_across(k1_score:k4_score))) %>%
  mutate(attitude_total = sum(c_across(k5_score:k8_score))) %>%
  select(knowledge_total, attitude_total,everything()) 

aa_sub = aa %>% select(ID,knowledge_total:k8_score, intervention)
```

## 干预/对照情况，以及一些细节修改

### 单看态度与认知的数据集

``` r
# 单看态度与认知的数据集
tbl_aa = tableby(intervention ~ . , data = aa_sub[,-1])
summary(tbl_aa) %>%
  knitr::kable()
```

|                      | 0 (N=974)         | 1 (N=855)         | Total (N=1829)    | p value  |
| -------------------- | :---------------- | :---------------- | :---------------- | :------- |
| **knowledge\_total** |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 40.152 (6.096)    | 43.400 (6.403)    | 41.670 (6.447)    |          |
| Range                | 19.000 - 60.000   | 19.000 - 58.000   | 19.000 - 60.000   |          |
| **attitude\_total**  |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 211.052 (27.918)  | 197.829 (32.479)  | 204.871 (30.842)  |          |
| Range                | 123.000 - 293.000 | 116.000 - 270.000 | 116.000 - 293.000 |          |
| **k1\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 7.857 (1.823)     | 8.342 (1.942)     | 8.084 (1.894)     |          |
| Range                | 1.000 - 13.000    | 2.000 - 14.000    | 1.000 - 14.000    |          |
| **k2\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 9.122 (1.918)     | 9.619 (1.939)     | 9.354 (1.943)     |          |
| Range                | 3.000 - 14.000    | 4.000 - 14.000    | 3.000 - 14.000    |          |
| **k3\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 10.534 (2.353)    | 11.363 (2.403)    | 10.921 (2.412)    |          |
| Range                | 3.000 - 17.000    | 3.000 - 17.000    | 3.000 - 17.000    |          |
| **k4\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 12.639 (2.380)    | 14.077 (2.421)    | 13.311 (2.504)    |          |
| Range                | 4.000 - 17.000    | 3.000 - 17.000    | 3.000 - 17.000    |          |
| **k5\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 67.159 (10.730)   | 63.705 (11.706)   | 65.545 (11.326)   |          |
| Range                | 36.000 - 100.000  | 34.000 - 98.000   | 34.000 - 100.000  |          |
| **k6\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 73.032 (10.428)   | 67.649 (12.060)   | 70.516 (11.535)   |          |
| Range                | 42.000 - 103.000  | 33.000 - 104.000  | 33.000 - 104.000  |          |
| **k7\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 57.228 (9.499)    | 54.184 (10.186)   | 55.805 (9.940)    |          |
| Range                | 28.000 - 87.000   | 29.000 - 82.000   | 28.000 - 87.000   |          |
| **k8\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 13.633 (4.175)    | 12.291 (4.388)    | 13.006 (4.327)    |          |
| Range                | 6.000 - 30.000    | 6.000 - 28.000    | 6.000 - 30.000    |          |

接下来我们还需将`态度与认知`映射到之前的学生数据集上，一下是一些基本的清理操作：

``` r
# 05.05清理后得到的数据集命名为“t”(temp)。（不好意思对数据不是很清楚，所以命名很乱，我会强调但你们也要看清楚）
# 我们还需要清理或进行如下操作：
# 1. depression 得分，在之前的代码已经做出修改
# 2. 年级名 - 改为了ordinal categorical variables。 4 < 5 <6
# 3. 匹配态度和认知得分
# `t` 共有1811的记录，而态度与认知数据集共有1829个记录，在这里我们以`t`为基准哈

t_aa = left_join(t, aa_sub, by="ID")
t_aa = t_aa %>%
  mutate(grade = recode(grade, 
                        "四" = "4",
                        "五" = "5",
                        "六" = "6"),
         grade = factor(grade, levels = c("4", "5", "6"))) %>%
  filter(!is.na(knowledge_total))
# `t_aa` 合并了05.05更新的数据集 `t`和05.06更新的`认知与态度`数据集
```

### 学生态度与认知简单一瞥

以下数据，全部都是花名册内的学生数据。

``` r
# 单看态度与认知的数据集
t_aa_sub = t_aa %>% select(knowledge_total, attitude_total, k1_score, k2_score, k3_score, k4_score, k5_score, k6_score, k7_score, k8_score, intervention_h)

tbl_t_aa = tableby(intervention_h ~ . , data = t_aa_sub)

summary(tbl_t_aa) %>%
  knitr::kable()
```

|                      | 0 (N=957)         | 1 (N=847)         | Total (N=1804)    | p value  |
| -------------------- | :---------------- | :---------------- | :---------------- | :------- |
| **knowledge\_total** |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 40.158 (6.114)    | 43.436 (6.392)    | 41.697 (6.455)    |          |
| Range                | 19.000 - 60.000   | 19.000 - 58.000   | 19.000 - 60.000   |          |
| **attitude\_total**  |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 210.933 (28.019)  | 197.588 (32.460)  | 204.667 (30.904)  |          |
| Range                | 123.000 - 293.000 | 116.000 - 270.000 | 116.000 - 293.000 |          |
| **k1\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 7.861 (1.827)     | 8.346 (1.945)     | 8.089 (1.899)     |          |
| Range                | 1.000 - 13.000    | 2.000 - 14.000    | 1.000 - 14.000    |          |
| **k2\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 9.123 (1.918)     | 9.625 (1.943)     | 9.359 (1.945)     |          |
| Range                | 3.000 - 14.000    | 4.000 - 14.000    | 3.000 - 14.000    |          |
| **k3\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 10.527 (2.359)    | 11.383 (2.384)    | 10.928 (2.408)    |          |
| Range                | 3.000 - 17.000    | 3.000 - 17.000    | 3.000 - 17.000    |          |
| **k4\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 12.647 (2.371)    | 14.083 (2.420)    | 13.321 (2.499)    |          |
| Range                | 4.000 - 17.000    | 3.000 - 17.000    | 3.000 - 17.000    |          |
| **k5\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 67.121 (10.735)   | 63.604 (11.683)   | 65.470 (11.324)   |          |
| Range                | 36.000 - 100.000  | 34.000 - 98.000   | 34.000 - 100.000  |          |
| **k6\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 73.036 (10.464)   | 67.576 (12.067)   | 70.472 (11.568)   |          |
| Range                | 42.000 - 103.000  | 33.000 - 104.000  | 33.000 - 104.000  |          |
| **k7\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 57.168 (9.534)    | 54.106 (10.162)   | 55.731 (9.949)    |          |
| Range                | 28.000 - 87.000   | 29.000 - 82.000   | 28.000 - 87.000   |          |
| **k8\_score**        |                   |                   |                   | \< 0.001 |
| Mean (SD)            | 13.608 (4.150)    | 12.301 (4.389)    | 12.994 (4.313)    |          |
| Range                | 6.000 - 30.000    | 6.000 - 28.000    | 6.000 - 30.000    |          |

intervention0人, control0人。

### 导出05.06更新的`t_aa`

``` r
write.csv(t_aa, './data/t_aa_0506.csv', row.names = F)
```

## 0506更新：处理`家长问卷`

``` r
parents = read_xlsx('./parents/家长问卷_20210502.xlsx')
```

### 处理

  - 去除无法匹配的记录

  - 创建所需变量

<!-- end list -->

``` r
# 去除无法匹配的记录
parents_inlist = parents %>%
  filter(ID %in% code$X2)

# 创建所需变量
## 设定匹配规则（根据截图）

public_intervention = tibble(school = as.character(11:18),
                             intervention = c(0,1,0,1,0,0,0,1),
                             public = c(0,1,1,1,0,0,1,1))

parents_matched = parents_inlist %>%
  mutate(school = str_sub(ID,1,2),
         school_class = str_sub(ID,3,4)) %>%
  left_join(., grade_matched, by="ID") %>%
  left_join(., public_intervention) %>%
  mutate(grade = str_sub(grade, 1, 1),
         grade = recode(grade, 
                        "四" = "4",
                        "五" = "5",
                        "六" = "6"),
         grade = factor(grade, levels = c("4", "5", "6"))) %>%
  select(grade, school, school_class, intervention, public, everything()) 
```

    ## Joining, by = "school"

共有1452个家长匹配成功，36个家长匹配失败（共计 1488 人）。新创建的五个变量(`school`, `intervention`,
`public`, `grade`, `school`, `class`)
无缺失。

### simple check on `parents_matched`

``` r
skimr::skim(parents_matched %>% select(grade, school, school_class, intervention, public))
```

    ## Skim summary statistics
    ##  n obs: 1452 
    ##  n variables: 5 
    ##  group variables:  
    ## 
    ## ── Variable type:character ────────────────────────────────────────────────────────────────────────────────
    ##      variable missing complete    n min max empty n_unique
    ##        school       0     1452 1452   2   2     0        8
    ##  school_class       0     1452 1452   2   2     0       45
    ## 
    ## ── Variable type:factor ───────────────────────────────────────────────────────────────────────────────────
    ##  variable missing complete    n n_unique                    top_counts
    ##     grade       0     1452 1452        3 6: 527, 5: 510, 4: 415, NA: 0
    ##  ordered
    ##    FALSE
    ## 
    ## ── Variable type:numeric ──────────────────────────────────────────────────────────────────────────────────
    ##      variable missing complete    n mean   sd p0 p25 p50 p75 p100     hist
    ##  intervention       0     1452 1452 0.41 0.49  0   0   0   1    1 ▇▁▁▁▁▁▁▆
    ##        public       0     1452 1452 0.48 0.5   0   0   0   1    1 ▇▁▁▁▁▁▁▇

### 导出`parents_matched`

``` r
write.csv(parents_matched, './parents/parents_matched.csv', row.names = FALSE)
```

### 导出`t` 和 `aa_sub`

``` r
write.csv(t, './t.csv', row.names = F)
write.csv(aa_sub, './aa_sub.csv', row.names = F)
```
